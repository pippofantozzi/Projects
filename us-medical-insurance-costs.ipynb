{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Medical Insurance Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\n",
      "________________________________________________________________________________________________________________________________________\n",
      "This insurance csv file contains a list of approximately 1350 clients, with the following attributes:  \n",
      "    Age, Sex, BMI, Children, Smoker, Region and Charges.\n",
      "To analyze this dataset, I first extracted all of the data from the file, and separated each column into a separate variable with lists. \n",
      "\n",
      "I decided to analyze the dataset and extract information in the following ways using this data: \n",
      "1) Find the most common client, aka the most common value in each column\n",
      "2) Seperate each column into more digestible blocks, with their proportion to the whole\n",
      "   (How many clients are between 18 - 23? What percentage of clients is that of the total?)\n",
      "3) Calculate which two collumns have the highest correlation with each other (does an increase in age show a correlation with increase in BMI?)\n",
      "4) Calculate a correlation between an Attribute and the Number of Clients (As age increases, are there more or less clients?)\n",
      "5) Calculate the Mean, Mode, Median, Max, Min, and 3 most common Ranges for \n",
      "each attribute/collumn in each region(What is the most common age range in SouthWest area?)\n",
      "\n",
      "Given that, heres what I was able to calculate:\n",
      "_________________________________________________________________________________________________________________________________________\n",
      "Most Common Attribute Values:\n",
      "________________________________________________________________________________________________________________________\n",
      "         Most Common Value:  Amount:  Proportion:  Percentage: \n",
      "Age                    18.0       69          0.05        5.16%\n",
      "Sex                    male      676          0.51       50.52%\n",
      "BMI                    30.0      102          0.08        7.62%\n",
      "Children                0.0      574          0.43        42.9%\n",
      "Smoker                   no     1064          0.80       79.52%\n",
      "Region            southeast      364          0.27        27.2%\n",
      "Charges              1632.0        3          0.00        0.22%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "In this table, you can see the most prominent client attributes, the amount of times they appear in the dataset, \n",
      "the proportion of their amount compared to all others in the dataset (For age, 69 clients are 18, 69/1350 total clients is 0.05 of the total), \n",
      "and the proportion.\n",
      "\n",
      "The most significant discoveries from this would most likely be smoker, age, BMI and children. \n",
      "I say this because Sex is 50/50, so for male to be 0.1% ,dominant isnt significant whatsover. \n",
      "There are 4 regions so each should have 25% ,or so clients, so 27% ,isnt too out of the curve, \n",
      "and charges has thousands of different values so you cant say one value is significant.\n",
      "\n",
      "In terms of the more statistically significant ones, the fact that 80% ,of people are non smokers is interesting \n",
      "because there are two options, Yes/No making it 50/50 assuming nothing, so a 30%, deviation from this shows that in fact \n",
      "people who are clients here are prone to not smoke.\n",
      "\n",
      "The children data is interesting as well because with the max age being 4 in the dataset, all children should be about 20% ,each assuming nothing, \n",
      "therefore for 0 to have 42% ,of the total clients in terms of children amount it is significant. \n",
      "This could imply the people who are clients to this service tend to not have children, but this may also \n",
      "be explained by the fact that most clients are 18, so many others could be very young as well and not have children yet which would explain this.\n",
      "\n",
      "_____________________________________________________________________________\n",
      "Proportions for Age :\n",
      "________________________________________________________________________________________________________________________\n",
      "        Count Percentage\n",
      "18 - 23   222     16.59%\n",
      "23 - 28   140     10.46%\n",
      "28 - 33   135     10.09%\n",
      "33 - 38   127      9.49%\n",
      "38 - 43   131      9.79%\n",
      "43 - 48   141     10.54%\n",
      "48 - 53   144     10.76%\n",
      "53 - 58   134     10.01%\n",
      "58 - 63   119      8.89%\n",
      "63 - 64    23      1.72%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Proportions for Children :\n",
      "________________________________________________________________________________________________________________________\n",
      "      Count Percentage\n",
      "0 - 1   574      42.9%\n",
      "1 - 2   324     24.22%\n",
      "2 - 3   240     17.94%\n",
      "3 - 4   157     11.73%\n",
      "4 - 5    25      1.87%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Proportions for BMI :\n",
      "________________________________________________________________________________________________________________________\n",
      "        Count Percentage\n",
      "16 - 20    29      2.17%\n",
      "20 - 24   132      9.87%\n",
      "24 - 28   251     18.76%\n",
      "28 - 32   349     26.08%\n",
      "32 - 36   282     21.08%\n",
      "36 - 40   185     13.83%\n",
      "40 - 44    80      5.98%\n",
      "44 - 48    22      1.64%\n",
      "48 - 52     6      0.45%\n",
      "52 - 53     0       0.0%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Proportions for Charges :\n",
      "________________________________________________________________________________________________________________________\n",
      "              Count Percentage\n",
      "1122 - 7387     536     40.06%\n",
      "7387 - 13652    398     29.75%\n",
      "13652 - 19917   129      9.64%\n",
      "19917 - 26182    86      6.43%\n",
      "26182 - 32447    35      2.62%\n",
      "32447 - 38712    59      4.41%\n",
      "38712 - 44977    57      4.26%\n",
      "44977 - 51242    32      2.39%\n",
      "51242 - 57507     2      0.15%\n",
      "57507 - 63770     3      0.22%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Proportions for Sex :\n",
      "________________________________________________________________________________________________________________________\n",
      "       Count Percentage\n",
      "female   662     49.48%\n",
      "male     676     50.52%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Proportions for Smoker :\n",
      "________________________________________________________________________________________________________________________\n",
      "    Count Percentage\n",
      "no   1064     79.52%\n",
      "yes   274     20.48%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Proportions for Region :\n",
      "________________________________________________________________________________________________________________________\n",
      "          Count Percentage\n",
      "northeast   324     24.22%\n",
      "northwest   325     24.29%\n",
      "southeast   364      27.2%\n",
      "southwest   325     24.29%\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "The benefit of the following tables is not only that it gives a better picture of the\n",
      "overall data instead of the only the highest occuring point, but also it divides the data into ranges, making for a better representation\n",
      "of which group is more prominent. \n",
      "\n",
      "For instance, the Charges and BMI columns had thousands of different numbers, unique to the decimal! So to find the most occuring number wont show much\n",
      "as all values are mostly unique. Having said this, by dividing our values into ranges as we have, we are able to have a more accurite picture of the data!\n",
      "\n",
      "So what have we found here? Aside from the Categorical Values we already mentioned in the previous table (Smoker, Sex, Region), some other columns really \n",
      "shine hear such as the aforementioned Charges column. Now that we seperated it into ranges, and how many clients are inside each range, we are able to accurately\n",
      "tell that almost 40%, of the clients pay the least amount of insurance, almost another 30%, pay for the second cheapest range, and the rest of the ranges pay less \n",
      "than 10%, decreasing the number each time more and more the more expensive the insurance is.\n",
      "\n",
      "This might be because people cant afford higher and higher fees, or it might be because, most of them are healthy enough to pay cheaper fees, this is further \n",
      "illustrated by the fact that in the Age proportions, where almost all age ranges are about 10%, except for 18-23 which are the only ones above 10%, at 16%! This \n",
      "larger group of younger people would definitely drive some of the Charges to be cheaper for the younger Clients\n",
      "\n",
      "The BMI on the other hand seems to be the only one who doesnt have a decreasing range scale, where instead it looks more like a normal curve, with little people\n",
      "having the lowest BMI, then steadily increasing until it reaches its peak at BMI 28-32 with 26%, then a steady decrease again towards the end.\n",
      "\n",
      "And lastly, for Children over 42%, dont have children with 25%, having 1 child. And like many other data tables, this one also has a rapid decline\n",
      "with fewer and fewer clients having more children. This could be because of economic development, or for economic reasons in general. \n",
      "\n",
      "___________________________________________________________________________________________________________________________\n",
      "Correlations Between Attributes/Collumns:\n",
      "________________________________________________________________________________________________________________________\n",
      "                        Pearsons Correlation Coefficient\n",
      "Temp_Smoker - Charges                           0.787251\n",
      "Age - Charges                                   0.299009\n",
      "BMI - Charges                                   0.198795\n",
      "Age - BMI                                       0.109527\n",
      "Temp_Sex - Temp_Smoker                          0.076185\n",
      "Children - Charges                              0.067997\n",
      "Temp_Sex - Charges                              0.057291\n",
      "Temp_Sex - BMI                                  0.044979\n",
      "Age - Children                                  0.042469\n",
      "Temp_Sex - Children                             0.017163\n",
      "BMI - Children                                  0.013915\n",
      "Children - Temp_Smoker                          0.007673\n",
      "BMI - Temp_Smoker                               0.004301\n",
      "Age - Temp_Sex                                 -0.020856\n",
      "Age - Temp_Smoker                              -0.025019\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "Correlations Between Attribute and Number of Clients:\n",
      "________________________________________________________________________________________________________________________\n",
      "          Pearsons Correlation Coefficient\n",
      "Children                         -0.973521\n",
      "Charges                          -0.815827\n",
      "Age                              -0.723995\n",
      "BMI                              -0.461056\n",
      "\n",
      "________________________________________________________________________________________________________________________\n",
      "So here we have two types of correlation analysis. The first is a correlation between each possible\n",
      "combination of columns. Is there a correlation between Age and BMI? Age and Number of Children? So on. The second is a correlation \n",
      "of a column with its own count, for instance, as the values of age increase, does the number of clients increase as well? And so on.\n",
      "\n",
      "For the first correlation, perhaps the most significant observations are the following:\n",
      "- The strongest postitive correlation is between Smoking and Charges, which is fairly obvious and doesnt require much explanation\n",
      "- The second strongest correlation is a positive one which shows how Age is one of the (although weak) strongest correlations with \n",
      "how much someone is charged after smoking or not\n",
      "- The last, and arguably relevant observation is the third strongest yet very weak correlation which shows how BMI plays a role but not\n",
      "even close to the biggest role in how much someone is charged\n",
      "\n",
      "For the Second and final correlation, here is what was found:\n",
      "- According to this table and the previosly mentioned findings, people are likely to have no children in this clientel dataset, if they do, it\n",
      "will most likely be one child, and every increase of another child is exponentially more unlikely than the previous one.\n",
      "- Charges have a very strong negative correlation, indicating that the more expensive insurance is the less people have it. Again, this may be\n",
      "because most people in this dataset are young, dont smoke, and are generally healthy so they pay less, but it could also be as simple as less people\n",
      "are able to afford more expensive insurances, and oftentime extremelly expensive insurances are due to costly diseases that dont happen to every client\n",
      "very often\n",
      "-For Age as mentioned most clients are younger, and there is a small decrease in clients the older they are\n",
      "-For BMI, as we saw, it is one of the only ones with a seemingly normal curve, and therefore has less of a linear and strong correlation than the rest.\n",
      "\n",
      "___________________________________________________________________________________________________________________________\n",
      "Regions Findings:\n",
      "________________________________________________________________________________________________________________________\n",
      "SOUTHWEST CATEGORICAL DICHOTOMOUS FINDINGS \n",
      "\n",
      "========================================================\n",
      "Sex: \n",
      "\n",
      "Most common:  male\n",
      "Quantity:  163  Percentage:  50.15 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "Smoker: \n",
      "\n",
      "Most common:  No\n",
      "Quantity:  267  Percentage:  82.15 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "SOUTHEAST CATEGORICAL DICHOTOMOUS FINDINGS \n",
      "\n",
      "========================================================\n",
      "Sex: \n",
      "\n",
      "Most common:  male\n",
      "Quantity:  189  Percentage:  51.92 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "Smoker: \n",
      "\n",
      "Most common:  No\n",
      "Quantity:  273  Percentage:  75.0 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "NORTHWEST CATEGORICAL DICHOTOMOUS FINDINGS \n",
      "\n",
      "========================================================\n",
      "Sex: \n",
      "\n",
      "Most common:  female\n",
      "Quantity:  164  Percentage:  50.46 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "Smoker: \n",
      "\n",
      "Most common:  No\n",
      "Quantity:  267  Percentage:  82.15 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "NORTHEAST CATEGORICAL DICHOTOMOUS FINDINGS \n",
      "\n",
      "========================================================\n",
      "Sex: \n",
      "\n",
      "Most common:  male\n",
      "Quantity:  163  Percentage:  50.31 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "Smoker: \n",
      "\n",
      "Most common:  No\n",
      "Quantity:  257  Percentage:  79.32 %\n",
      "-------------------------------------------------- \n",
      " \n",
      "For these more categorical attributes, we can see that even by separating them by their\n",
      "respective regions, they all seem to have a highly similar value showing no statistically significant impact on the clients depending\n",
      "on their region in terms of these categorical attributes.\n",
      "\n",
      "___________________________________________________________________________________________________________________________\n",
      "SOUTHWEST FINDINGS:\n",
      "_________________________________________________________________________________________________________\n",
      "                   Highest Range  Range Amount     Second Highest Range  \\\n",
      "Age           Between 19 and 24:            59       Between 49 and 54:   \n",
      "Children        Between 0 and 1:           138         Between 1 and 2:   \n",
      "BMI           Between 29 and 33:            85       Between 33 and 37:   \n",
      "Charges   Between 1242 and 7507:           139  Between 7507 and 13772:   \n",
      "\n",
      "          Second Range Amount       Third Highest Range  Third Range Amount  \\\n",
      "Age                        36        Between 54 and 59:                  33   \n",
      "Children                   78          Between 2 and 3:                  57   \n",
      "BMI                        75        Between 37 and 41:                  36   \n",
      "Charges                   106  Between 13772 and 20037:                  24   \n",
      "\n",
      "              Max     Min    Mode  Median      Mean  \n",
      "Age          64.0    19.0    19.0    39.0     39.46  \n",
      "Children      5.0     0.0     0.0     1.0      1.14  \n",
      "BMI          48.0    17.0    30.0    30.0     30.62  \n",
      "Charges   52591.0  1242.0  1242.0  8799.0  12346.93  \n",
      "\n",
      "_________________________________________________________________________________________________________\n",
      "SOUTHEAST FINDINGS:\n",
      "_________________________________________________________________________________________________________\n",
      "                   Highest Range  Range Amount     Second Highest Range  \\\n",
      "Age           Between 18 and 23:            63       Between 43 and 48:   \n",
      "Children        Between 0 and 1:           157         Between 1 and 2:   \n",
      "BMI           Between 36 and 40:            80       Between 40 and 44:   \n",
      "Charges   Between 1122 and 7387:           147  Between 7387 and 13652:   \n",
      "\n",
      "          Second Range Amount       Third Highest Range  Third Range Amount  \\\n",
      "Age                        39        Between 38 and 43:                  37   \n",
      "Children                   95          Between 2 and 3:                  66   \n",
      "BMI                        38        Between 44 and 48:                  16   \n",
      "Charges                    90  Between 13652 and 19917:                  39   \n",
      "\n",
      "              Max     Min    Mode  Median      Mean  \n",
      "Age          64.0    18.0    18.0    39.0     38.94  \n",
      "Children      5.0     0.0     0.0     1.0      1.05  \n",
      "BMI          53.0    20.0    34.0    33.0     33.34  \n",
      "Charges   63770.0  1122.0  1136.0  9294.5  14735.41  \n",
      "\n",
      "_________________________________________________________________________________________________________\n",
      "NORTHWEST FINDINGS:\n",
      "_________________________________________________________________________________________________________\n",
      "                   Highest Range  Range Amount     Second Highest Range  \\\n",
      "Age           Between 19 and 24:            62       Between 49 and 54:   \n",
      "Children        Between 0 and 1:           132         Between 1 and 2:   \n",
      "BMI           Between 25 and 29:            92       Between 29 and 33:   \n",
      "Charges   Between 1621 and 7886:           146  Between 7886 and 14151:   \n",
      "\n",
      "          Second Range Amount       Third Highest Range  Third Range Amount  \\\n",
      "Age                        35        Between 54 and 59:                  33   \n",
      "Children                   74          Between 2 and 3:                  66   \n",
      "BMI                        88        Between 33 and 37:                  56   \n",
      "Charges                    90  Between 14151 and 20416:                  30   \n",
      "\n",
      "              Max     Min    Mode  Median      Mean  \n",
      "Age          64.0    19.0    19.0    39.0     39.20  \n",
      "Children      5.0     0.0     0.0     1.0      1.15  \n",
      "BMI          43.0    17.0    28.0    29.0     29.21  \n",
      "Charges   60021.0  1621.0  1640.0  8966.0  12417.58  \n",
      "\n",
      "_________________________________________________________________________________________________________\n",
      "NORTHEAST FINDINGS:\n",
      "_________________________________________________________________________________________________________\n",
      "                   Highest Range  Range Amount     Second Highest Range  \\\n",
      "Age           Between 18 and 23:            52       Between 23 and 28:   \n",
      "Children        Between 0 and 1:           147         Between 1 and 2:   \n",
      "BMI           Between 28 and 32:            79       Between 32 and 36:   \n",
      "Charges   Between 1695 and 7960:           122  Between 7960 and 14225:   \n",
      "\n",
      "          Second Range Amount       Third Highest Range  Third Range Amount  \\\n",
      "Age                        35        Between 53 and 58:                  34   \n",
      "Children                   77          Between 2 and 3:                  51   \n",
      "BMI                        64        Between 36 and 40:                  31   \n",
      "Charges                   103  Between 14225 and 20490:                  34   \n",
      "\n",
      "              Max     Min     Mode   Median      Mean  \n",
      "Age          64.0    18.0     18.0     39.5     39.27  \n",
      "Children      5.0     0.0      0.0      1.0      1.05  \n",
      "BMI          48.0    16.0     32.0     29.0     29.16  \n",
      "Charges   58571.0  1695.0  11658.0  10057.5  13406.35  \n",
      "\n",
      "_________________________________________________________________________________________________________\n",
      "Here we have an analysis of the nominal attributes in the dataset, but by seperating it into\n",
      "the clients from each region. The reason this was made was because one of my goals was calculating correlation between attributes. \n",
      "And when doing that, I realized that with nominal and categorical dichotomous variables this is fairly simple to do. However, Categorical \n",
      "values that are not dichotomous are a bit more complicated to perform this calculation and could give very skewed projections and calculations.\n",
      "\n",
      "It is for this reason that this entire section was created, it was a way to see if regions have an impact on all the other attributes.\n",
      "Now that his was made, that can be answered, and here is what was found:\n",
      "\n",
      "- Most Attributes seem to remain relatively constant and not change in between regions\n",
      "- Two Attributes that seem to stand out a bit more than the others is Charges and Age\n",
      "- It seems as if Easter regions have a large number of 18 year olds, then smaller, yet still large, ages after that, such as 7 20 year olds,\n",
      "and 6 21 year olds compared to the 34 18 year olds. The same applies to Western regions but with 19 years olds, they have no 18 year olds but\n",
      "have the same cluster of age group that Easter has with 18 year olds, but with 19 year olds having about 30 clients, and the following ages having\n",
      "on average 7 - 6 per age following that.\n",
      "- Also for Charges, Eastern Charges seem to be on average a slight bit more than Western Charges, almost $1000 more on average.\n",
      "\n",
      "___________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import scipy.stats as SS\n",
    "from statistics import mean,median,mode\n",
    "import Narration2\n",
    "import Narrations3\n",
    "\n",
    "\n",
    "with open('insurance.csv') as insurance: #This gets the insurance file, and puts it into a dictionary\n",
    "        reader = csv.reader(insurance)\n",
    "        Clients = {}\n",
    "        count = -1\n",
    "        for row in reader:\n",
    "            if count > -1:\n",
    "                Clients[count] = {'Age':row[0],'Sex':row[1],'BMI':row[2],'Children':row[3],'Smoker':row[4],'Region':row[5],'Charges':row[6]}\n",
    "            count+=1\n",
    "\n",
    "def Variables(): # This gets the variable with all the values, and separates each column into its own unique variable as a list\n",
    "    global Attributes, Categorical\n",
    "    Attributes = ['Age','Sex','BMI','Children','Smoker','Region','Charges']\n",
    "    Categorical = ['Sex','Smoker','Region']\n",
    "    global Numerical \n",
    "    Numerical = ['Age','Children','BMI','Charges']\n",
    "    for att in Attributes:\n",
    "        globals()[att] = [Clients[row][att] for row in Clients]\n",
    "Variables()\n",
    "\n",
    "def Numerical_Intervals(): #Calculates the intervals that will be used for range calculations later\n",
    "    global Intervals\n",
    "    Intervals = {}\n",
    "    for Num in Numerical:\n",
    "        temp_Interval = globals()[Num]\n",
    "        if(Num != 'Children'):\n",
    "            temp_Interval = list(map(float,temp_Interval))\n",
    "            Max = max(temp_Interval)\n",
    "            Min = min(temp_Interval)\n",
    "            Rounded_Intervals = round((Max-Min)/10)\n",
    "        elif(Num == 'Children'):\n",
    "            Rounded_Intervals = 1\n",
    "        Intervals[Num] = Rounded_Intervals\n",
    "Numerical_Intervals()\n",
    "\n",
    "\n",
    "def MostCommon(): #Finds the most common value for every attribute in the dataset\n",
    "    Most_Common = {}\n",
    "    for att in Attributes:\n",
    "        temp = globals()[att]\n",
    "        Counter_temp = Counter(temp).most_common(1)[0]\n",
    "        Most_Common[att] = {\"Most Common Value:\":Counter_temp[0],\"Amount:\":Counter_temp[1],\"Proportion: \":round(Counter_temp[1]/len(temp),2),\"Percentage: \":str(round((Counter_temp[1]/len(temp))*100,2))+\"%\"}    \n",
    "    return Most_Common\n",
    "\n",
    "def MakeNumber(): #Gets the numerical variables from the dataset and makes them float instead of string\n",
    "      for Num in Numerical:\n",
    "        temp_num = globals()[Num]\n",
    "        temp_num = list(map(float,temp_num))\n",
    "        temp_list = list(np.around(np.array(temp_num),0))\n",
    "        globals()[Num] = temp_list  \n",
    "\n",
    "def Proportions(): #Calculates all the proportions and puts the info into a dictionary instead of showcasing it as just a print statement\n",
    "    global Min,Max,Remainder, Interval, temp_list, ProportionsDict, Calculation_Of_Correlation\n",
    "    ProportionsDict = {}\n",
    "    for Num in Numerical:\n",
    "        temp_num = globals()[Num]\n",
    "        temp_num = list(map(float,temp_num))\n",
    "        temp_list = list(np.around(np.array(temp_num),0))\n",
    "        Interval = Intervals[Num]\n",
    "        Min = int(min(temp_list))\n",
    "        Max = int(max(temp_list))\n",
    "        Start = Min\n",
    "        End = Min + Interval\n",
    "        Remainder = round((Max-Min)%Intervals[Num])\n",
    "        ProportionsDict[Num] = {\"|\":\"|\"}\n",
    "        for i in range(Min,Max-Remainder,Interval):\n",
    "            count = sum(i >= Start and i < End for i in temp_list)\n",
    "            Start_End = str(Start)+\" - \"+str(End)\n",
    "            ProportionsDict[Num].update({Start_End:{\"Count\":count,\"Percentage\":(str(round((count/len(temp_list))*100,2))+\"%\")}})\n",
    "            if(i != Max-Interval-Remainder):\n",
    "                Start = End\n",
    "                End = End + Interval\n",
    "            elif(Remainder > 0):\n",
    "                Start = End\n",
    "                End = End + Remainder\n",
    "                count = sum(i >= Start and i < End for i in temp_list)\n",
    "                Start_End = str(Start)+\" - \"+str(End)\n",
    "                ProportionsDict[Num].update({Start_End:{\"Count\":count,\"Percentage\":(str(round((count/len(temp_list))*100,2))+\"%\")}})\n",
    "\n",
    "    for Categ in Categorical:\n",
    "        temp_cat = globals()[Categ]\n",
    "        counter = sorted(Counter(temp_cat).items())\n",
    "        ProportionsDict[Categ] = {\"|\":\"|\"}\n",
    "        for k,v in counter:\n",
    "            ProportionsDict[Categ].update({k:{\"Count\":v,\"Percentage\":(str(round((v/len(temp_list))*100,2))+\"%\")}})\n",
    "    return ProportionsDict\n",
    "\n",
    "def Correlation_Attribute_Attribute(): #Sees if there is a correlation between two attributes (Smoker and Charges) Except for Region\n",
    "    global Correlations\n",
    "    Attributes_Modified = Atts_For_Correlation()\n",
    "    MakeNumber()\n",
    "    Comb = list(combinations(Attributes_Modified,2))\n",
    "    Correlations_Att_Att = {}\n",
    "    for possible_combinations in Comb:\n",
    "        corr, pv = SS.pearsonr(globals()[possible_combinations[0]],globals()[possible_combinations[1]])\n",
    "        Correlations_Att_Att[possible_combinations[0]+' - '+possible_combinations[1]] = corr\n",
    "    return Correlations_Att_Att\n",
    "\n",
    "def Correlation_Attribute_Number_Of_Clients_Numericals():\n",
    "    Correlations_Att_Count = {}\n",
    "    temp_dict = {}\n",
    "    temp_range_list = []\n",
    "    for Num in Numerical:\n",
    "        temp_dict[Num] = []\n",
    "        for k in ProportionsDict[Num].keys():\n",
    "            if(k != \"|\"):\n",
    "                x = k.rfind('-')\n",
    "                new_key = int(k[:x])\n",
    "                temp_dict[Num] += [new_key]\n",
    "        values = list(ProportionsDict[Num].values())[1:]\n",
    "        values = [x[\"Count\"] for x in values]\n",
    "        corr, pv = SS.pearsonr(temp_dict[Num],values)\n",
    "        Correlations_Att_Count[Num] = corr\n",
    "        \n",
    "    return Correlations_Att_Count\n",
    "        \n",
    "#def Dichotomous_Categorical_To_Binary_Integer(): \n",
    "def Atts_For_Correlation():#Modifies the Attribute list so that instead of strings the categoricals are binary (1 or 0) instead of (yes or no) for smokers\n",
    "    global Temp_Sex,Temp_Smoker, Attributes_Modified\n",
    "    Attributes_Modified = []\n",
    "    Temp_Sex = [0 if sex == \"female\" else 1 for sex in Sex]\n",
    "    Temp_Smoker = [0 if smo == \"no\" else 1 for smo in Smoker]\n",
    "    for i in range(len(Attributes)):\n",
    "        if(Attributes[i] != \"Region\"):\n",
    "            if(Attributes[i] == \"Sex\"):\n",
    "                Attributes_Modified.append(\"Temp_Sex\")\n",
    "            elif(Attributes[i] == \"Smoker\"):\n",
    "                Attributes_Modified.append(\"Temp_Smoker\")\n",
    "            else:\n",
    "                Attributes_Modified.append(Attributes[i])\n",
    "    return Attributes_Modified\n",
    "\n",
    "def Regions_Calculations(): #Checks highest attribute count in each region, but also checks if divided into 4 parts which parts contain which region the most\n",
    "    #Find most common values of each, for all attributes connected to southwest, which att is most common for each att\n",
    "    Atts_For_Correlation()\n",
    "    global Regions_Calculations_Dict\n",
    "    Possible_Regions = [\"southwest\",\"southeast\",\"northwest\",\"northeast\"]\n",
    "    Regions_Calculations_Dict = {}\n",
    "    Passed = False\n",
    "    \n",
    "    for pr in Possible_Regions:\n",
    "        Passed = False\n",
    "        for att in Attributes_Modified:\n",
    "            if Passed == False:\n",
    "                Regions_Calculations_Dict[pr] = {att:[]}\n",
    "            Regions_Calculations_Dict[pr].update({att:[]})\n",
    "            Passed = True\n",
    "            Region_Att = list(zip(Region,globals()[att]))\n",
    "            for k,v in Region_Att:\n",
    "                if pr in k:\n",
    "                    Regions_Calculations_Dict[pr][att].append(v)\n",
    "            Regions_Calculations_Dict[pr][att] = sorted(Regions_Calculations_Dict[pr][att])\n",
    "    return Regions_Calculations_Dict\n",
    "\n",
    "def Regions_Findings():\n",
    "    global southeast,southwest,northeast,northwest\n",
    "    Regions_Calculations_Dict = Regions_Calculations()\n",
    "    Calcs = [\"Max\",\"Min\",\"Mode\",\"Median\",\"Mean\"]\n",
    "    Possible_Regions = [\"southwest\",\"southeast\",\"northwest\",\"northeast\"]\n",
    "    RegionsDictTesting = {}\n",
    "    Testing = {}\n",
    "    for Re in Possible_Regions:\n",
    "        print(Re.upper(),\"CATEGORICAL DICHOTOMOUS FINDINGS\",\"\\n\")\n",
    "        print(\"========================================================\")\n",
    "        for Cat in [\"Temp_Sex\",\"Temp_Smoker\"]:\n",
    "            temp_cat = Regions_Calculations_Dict[Re][Cat]\n",
    "            cat_counter = Counter(Regions_Calculations_Dict[Re][Cat])\n",
    "            cat_list = list(cat_counter)\n",
    "            mc = cat_counter.most_common(1)[0]\n",
    "            if(Cat == \"Temp_Sex\"):\n",
    "                if mc[0] == 0:\n",
    "                    sex = \"female\"\n",
    "                else:\n",
    "                    sex = \"male\"\n",
    "                print(\"Sex: \\n\")\n",
    "                print(\"Most common: \",sex)\n",
    "                print(\"Quantity: \",mc[1],\" Percentage: \",round(mc[1]/len(temp_cat)*100,2),\"%\")\n",
    "                print(\"-------------------------------------------------- \\n \")\n",
    "            if(Cat == \"Temp_Smoker\"):\n",
    "                if mc[0] == 0:\n",
    "                    smo = \"No\"\n",
    "                else:\n",
    "                    smo = \"Yes\"\n",
    "                print(\"Smoker: \\n\")\n",
    "                print(\"Most common: \",smo)\n",
    "                print(\"Quantity: \",mc[1],\" Percentage: \",round(mc[1]/len(temp_cat)*100,2),\"%\")\n",
    "                print(\"-------------------------------------------------- \\n \")\n",
    "        for Num in Numerical:\n",
    "                temp_num = Regions_Calculations_Dict[Re][Num]\n",
    "                temp_num = list(map(float,temp_num))\n",
    "                temp_list = list(np.around(np.array(temp_num),0))\n",
    "                Interval = Intervals[Num]\n",
    "                Min = int(min(temp_list))\n",
    "                Max = int(max(temp_list))\n",
    "                Start = Min\n",
    "                End = Min + Interval\n",
    "                Remainder = round((Max-Min)%Intervals[Num])\n",
    "                Highest = 0\n",
    "                SecondHighest = 0\n",
    "                ThirdHighest = 0\n",
    "                Range = \"\"\n",
    "                for i in range(Min,Max-Remainder,Interval):\n",
    "                    x = sum(i >= Start and i < End for i in temp_list)\n",
    "                    if(x > Highest):\n",
    "                        Highest = x\n",
    "                        Range = \"Between \"+str(Start)+\" and \"+str(End)+\":\"\n",
    "                    elif(x < Highest and x > SecondHighest):\n",
    "                        SecondHighest = x\n",
    "                        SecondRange = \"Between \"+str(Start)+\" and \"+str(End)+\":\"\n",
    "                    elif(x < SecondHighest and x > ThirdHighest):\n",
    "                        ThirdHighest = x\n",
    "                        ThirdRange = \"Between \"+str(Start)+\" and \"+str(End)+\":\"\n",
    "                    if(i != Max-Interval-Remainder):\n",
    "                        Start = End\n",
    "                        End = End + Interval\n",
    "                    elif(Remainder > 0):\n",
    "                        Start = End\n",
    "                        End = End + Remainder\n",
    "                        if(x > Highest):\n",
    "                            Highest = x\n",
    "                            Range = \"Between\",str(Start),\"and\",str(End),\":\"\n",
    "                RegionsDictTesting[Num] = {\"Highest Range\":Range,\"Range Amount\":Highest,\"Second Highest Range\":SecondRange,\"Second Range Amount\":SecondHighest,\"Third Highest Range\":ThirdRange,\"Third Range Amount\":ThirdHighest}\n",
    "                for calc in Calcs:\n",
    "                    RegionsDictTesting[Num].update({calc:round(eval(calc.lower())(temp_list),2)})\n",
    "        Testing[Re] = dict(RegionsDictTesting)\n",
    "    return Testing       \n",
    "\n",
    "MakeNumber()\n",
    "\n",
    "def To_Table():\n",
    "    print(Narration2.Intro)\n",
    "    print(\"\"\"Most Common Attribute Values:\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    Most_Common = MostCommon()\n",
    "    Header_Top,Header_Side, data = [],[],[]\n",
    "    for k,v in Most_Common.items():\n",
    "        Header_Side.append(k)\n",
    "        values = list(v.values())\n",
    "        keys = list(v.keys())\n",
    "        if keys not in Header_Top:\n",
    "            Header_Top = keys\n",
    "        data.append(values)\n",
    "    Most_Common_Table = pd.DataFrame(data,Header_Side,Header_Top)\n",
    "    print(Most_Common_Table)\n",
    "    print(\"\"\"\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    print(Narrations3.MostCommonDescription)\n",
    "    Proportions_Dict = Proportions()\n",
    "    for k,v in Proportions_Dict.items():\n",
    "        print(\"Proportions for\",k,\"\"\":\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "        Header_Top,Header_Side, data = [],[],[]\n",
    "        for key,value in v.items():\n",
    "            if(key not in \"|\"):\n",
    "                Header_Top.append(key)\n",
    "                values = list(value.values())\n",
    "                keys = list(value.keys())\n",
    "                if keys not in Header_Side:\n",
    "                    Header_Side.append(keys)\n",
    "                data.append(values)\n",
    "        Proportions_Table = pd.DataFrame(data,Header_Top,Header_Side)\n",
    "        print(Proportions_Table)\n",
    "        print(\"\"\"\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    print(Narrations3.Proportions_Description)\n",
    "    print(\"\"\"Correlations Between Attributes/Collumns:\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    Correlations_Between_Att = dict(sorted(Correlation_Attribute_Attribute().items(), key=lambda x: x[1], reverse=True))\n",
    "    Header_Top,Header_Side, data = [],[],[]\n",
    "    for k,v in Correlations_Between_Att.items():\n",
    "        Header_Side.append(k)\n",
    "        Header_Top = [\"Pearsons Correlation Coefficient\"]\n",
    "        data.append(v)\n",
    "    First_Correlations = pd.DataFrame(data,Header_Side,Header_Top)\n",
    "    print(First_Correlations)\n",
    "    \n",
    "    print(\"\"\"\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    print(\"\"\"Correlations Between Attribute and Number of Clients:\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    Correlation_Client_Amount = dict(sorted(Correlation_Attribute_Number_Of_Clients_Numericals().items(), key=lambda x: x[1], reverse=False))\n",
    "    Header_Top,Header_Side, data = [],[],[]\n",
    "    for k,v in Correlation_Client_Amount.items():\n",
    "        Header_Side.append(k)\n",
    "        Header_Top = [\"Pearsons Correlation Coefficient\"]\n",
    "        data.append(v)\n",
    "    Second_Correlation = pd.DataFrame(data,Header_Side,Header_Top)\n",
    "    print(Second_Correlation)\n",
    "\n",
    "    print(\"\"\"\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    print(Narrations3.Correlations_Description)\n",
    "    print(\"\"\"Regions Findings:\n",
    "________________________________________________________________________________________________________________________\"\"\")\n",
    "    Regions_Findings_Dict = Regions_Findings()\n",
    "    print(Narrations3.Regions_Categorical_Description)\n",
    "    Header_Top,Header_Side, data = [],[],[]\n",
    "    for k,v in Regions_Findings_Dict.items():\n",
    "        print(k.upper(),\"FINDINGS:\")\n",
    "        print(\"\"\"_________________________________________________________________________________________________________\"\"\")\n",
    "        Header_Top = (list((list(v.values())[0]).keys()))\n",
    "        Header_Side = list(v.keys())\n",
    "        for key,value in v.items():\n",
    "            data.append(list(value.values()))\n",
    "        Regions_Showcase = pd.DataFrame(data,Header_Side,Header_Top)\n",
    "        data = []\n",
    "        print(Regions_Showcase)\n",
    "        print(\"\"\"\n",
    "_________________________________________________________________________________________________________\"\"\")\n",
    "    print(Narrations3.Regions_Numerical_Description) \n",
    "\n",
    "\n",
    "To_Table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89d6e1bb8654f6b6f757cb58b657896d04255e103c852616e7bc7969a01d44d6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
